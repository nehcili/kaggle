{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HousingDataProcessor Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data, Loading, Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# data is first downloweded into DATA_PATH from \n",
    "# http://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_PATH = 'data'\n",
    "FILE_NAME = 'train.csv'\n",
    "\n",
    "def load_data(data_path=DATA_PATH, file_name=FILE_NAME, ratio=0.9):\n",
    "    # load everything into data\n",
    "    file_path = os.path.join(data_path, file_name)\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fit and Transform of Data: HousingDataProcessor class\n",
    "Below we implement the HousingData class. The purpose of this class is to write \n",
    "1. A data structure that contains the input data\n",
    "2. fit_transform raw data into processed data ready for ML application\n",
    "\n",
    "The fit functions consits of the following purpose:\n",
    "0. it assumes that 'SalePrice' is not a column of the data. The order of the columns of the data is fixed\n",
    "1. seperate the data into numerical and categorical data, records the names of these columns as self.num_ind and self.cat_ind\n",
    "2. fit by median of all ZERO_HEAVY_COLS columns\n",
    "3. fit numerical columns in (0,1) by MinMaxScaler, preserving the column order. \n",
    "4. fit by LabelEncoder and OneHotEncoder, preserving the column order\n",
    "\n",
    "The transform_function does the transform part of the above. Returns a sparse matrix with everything in it\n",
    "0. it assumes that 'SalePrice' is not a column of the data. The order of the columns of the data is fixed\n",
    "1. seperate the data into numerical and categorical data via self.num_ind and self.cat_ind\n",
    "2. fill missing categorical data by the string 'UofTMath'\n",
    "3. fill all the missing numerical data by the median\n",
    "4. for each numerical column which has heavy data present at value 0, create a new column with entry 1 if heavy data is present at 0 and with entry 0 otherwise. Then set the entry in the original numerical column from 0 to the median. Finally, append to the end the new binary column to the category columns and name 'name_of_original_numeric_colum_zero'\n",
    "5. LabelEncoder and OneHotEncoder transform on categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HousingDataProcessor(object):\n",
    "    def __init__(self): \n",
    "        self.num_ind = [] # list\n",
    "        self.cat_ind = []\n",
    "        self.cat_ind_augmented = None\n",
    "        \n",
    "        self.num_types = [int, np.int64, float, np.float64]\n",
    "        self.ZERO_HEAVY_COLS = ['GarageArea', 'TotalBsmtSF', 'MasVnrArea', 'BsmtFinSF1', \n",
    "                       'WoodDeckSF', '2ndFlrSF', 'OpenPorchSF', 'BsmtUnfSF', \n",
    "                       'EnclosedPorch', 'ScreenPorch', 'PoolArea', '3SsnPorch', \n",
    "                       'LowQualFinSF', 'MiscVal', 'BsmtFinSF2', 'YearRemodAdd']\n",
    "        self.ZERO_HEAVY_COLS_zero = []\n",
    "        for col in self.ZERO_HEAVY_COLS:\n",
    "            self.ZERO_HEAVY_COLS_zero.append(col + '_zero')\n",
    "            \n",
    "        \n",
    "        # numerical\n",
    "        self.imputer_nan = None # fill empty by 0\n",
    "        self.imputer_zero = None # fill 0 by median\n",
    "        self.scaler = None\n",
    "        \n",
    "        # categorical\n",
    "        self.encoders = {}\n",
    "        self.cat_1hots = {}\n",
    "        \n",
    "    # seperate_num_and_cat: self, pd.DataFrame --> list of strings, list of strings\n",
    "    # seperate numerical and non numerical columns in data\n",
    "    # returns nums, and cats. They are the indice of\n",
    "    # the numerical and categorical columns\n",
    "    def fit_seperate_num_and_cat(self, data):\n",
    "        for col in data.columns:\n",
    "            if data[col].dtype in self.num_types:\n",
    "                self.num_ind.append(col)\n",
    "            else:\n",
    "                self.cat_ind.append(col)\n",
    "\n",
    "        self.cat_ind_augmented = self.cat_ind + self.ZERO_HEAVY_COLS_zero\n",
    "\n",
    "    # fit_num_data: self, pd.DataFrame --> void\n",
    "    def fit_num_data(self, num_data):\n",
    "        temp = num_data.copy()\n",
    "        \n",
    "        #print(temp[self.ZERO_HEAVY_COLS])\n",
    "      \n",
    "        self.imputer_nan = SimpleImputer(fill_value=0)\n",
    "        temp = pd.DataFrame(self.imputer_nan.fit_transform(temp), columns=num_data.columns)\n",
    "        \n",
    "        self.imputer_zero = SimpleImputer(missing_values=0, strategy='median')\n",
    "        temp[self.ZERO_HEAVY_COLS] = pd.DataFrame(self.imputer_zero.fit_transform(temp[self.ZERO_HEAVY_COLS]),  \n",
    "                                                  columns=num_data[self.ZERO_HEAVY_COLS].columns)\n",
    "        \n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.scaler.fit(temp)\n",
    "    \n",
    "    def transform_num_data(self, num_data):\n",
    "        temp = num_data.copy()\n",
    "        \n",
    "        temp = pd.DataFrame(self.imputer_nan.transform(temp), columns=temp.columns)\n",
    "        \n",
    "        temp[self.ZERO_HEAVY_COLS] = pd.DataFrame(self.imputer_zero.transform(temp[self.ZERO_HEAVY_COLS]),  \n",
    "                                                  columns=temp[self.ZERO_HEAVY_COLS].columns)\n",
    "        temp = pd.DataFrame(self.scaler.transform(temp), columns=temp.columns)\n",
    "        \n",
    "        return temp\n",
    "\n",
    "\n",
    "    def fit_1hot(self, data, additional_data=None):\n",
    "        if additional_data != None:\n",
    "            temp = pd.concat([data, additional_data]).copy()\n",
    "        else:\n",
    "            temp = data.copy()\n",
    "            \n",
    "        for col in self.cat_ind_augmented:\n",
    "            print(col)\n",
    "            self.encoders[col] = LabelEncoder()\n",
    "            self.cat_1hots[col] = OneHotEncoder()\n",
    "\n",
    "            temp = self.encoders[col].fit_transform(temp[col])\n",
    "            self.cat_1hots[col].fit(temp.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = HousingDataProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.fit_seperate_num_and_cat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.fit_num_data(data[x.num_ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x.transform_num_data(data[x.num_ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning\n",
      "Street\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-221-d6ca77fb5493>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_1hot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat_ind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-216-1f4d30410831>\u001b[0m in \u001b[0;36mfit_1hot\u001b[1;34m(self, data, additional_data)\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat_1hots\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m             \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat_1hots\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "x.fit_1hot(data[x.cat_ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3]])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
