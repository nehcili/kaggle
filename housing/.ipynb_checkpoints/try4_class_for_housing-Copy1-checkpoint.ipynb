{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import warnings\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# data is first downloweded into DATA_PATH from \n",
    "# http://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "DATA_PATH = 'data'\n",
    "FILE_NAME = 'train.csv'\n",
    "\n",
    "def load_data(data_path=DATA_PATH, file_name=FILE_NAME, ratio=0.9):\n",
    "    # load everything into data\n",
    "    file_path = os.path.join(data_path, file_name)\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    slice_ind = int(data.shape[0]*ratio)\n",
    "    \n",
    "    return data.iloc[0:slice_ind], data.iloc[slice_ind:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.log(test['SalePrice'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. The HousingRegressor class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HousingRegressor(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.training_data = None\n",
    "        self.training_labels = None\n",
    "        self.scaler = None\n",
    "        self.regressor = None\n",
    "        self.Onehot_coders = {}\n",
    "        self.encoders = {}\n",
    "        self.ZERO_HEAVY_COLS = ['GarageArea', 'TotalBsmtSF', 'MasVnrArea', 'BsmtFinSF1', \n",
    "                       'WoodDeckSF', '2ndFlrSF', 'OpenPorchSF', 'BsmtUnfSF', \n",
    "                       'EnclosedPorch', 'ScreenPorch', 'PoolArea', '3SsnPorch', \n",
    "                       'LowQualFinSF', 'MiscVal', 'BsmtFinSF2', 'YearRemodAdd']\n",
    "        self.ZERO_HEAVY_COLS_zero = []\n",
    "    \n",
    "        for col in self.ZERO_HEAVY_COLS:\n",
    "            self.ZERO_HEAVY_COLS_zero.append(col + '_zero')\n",
    "    \n",
    "    # seperate_num_and_cat: self, pd.DataFrame --> list of strings, list of strings\n",
    "    # seperate numerical and non numerical columns in data\n",
    "    # returns nums, and cats. They are the indice of\n",
    "    # the numerical and categorical columns\n",
    "    def seperate_num_and_cat(self, data):\n",
    "        # numerical data type\n",
    "        cont_type = [int, np.int64, float, np.float64]\n",
    "\n",
    "        nums = []\n",
    "        cats = []\n",
    "\n",
    "        for col in data.columns:\n",
    "            if data[col].dtype in cont_type:\n",
    "                nums.append(col)\n",
    "                #data[col].to_numeric()\n",
    "            else:\n",
    "                cats.append(col)\n",
    "\n",
    "        return nums, cats #.astype(str)\n",
    "\n",
    "    # encode_fit: self, pd.DataFrame --> pd.DataFrame, list of LabelEncoder\n",
    "    # assumes input is a pd.DataFrame with dtype == str\n",
    "    # encodes each column in cats by LabelEncoder()\n",
    "    def encode_fit(self, cats):\n",
    "        encoded_cats = {}\n",
    "\n",
    "        for cat in cats.columns:\n",
    "            encoder = LabelEncoder()\n",
    "            encoded_cats[cat] = encoder.fit_transform(cats[cat]) # won't work if cats has missing value\n",
    "            #print(encoded_cats[cat])\n",
    "            self.encoders[cat] = encoder\n",
    "\n",
    "        return pd.DataFrame(encoded_cats) #, encoders\n",
    "    \n",
    "    # encode_transform: self, pd.DataFrame --> pd.DataFrame, list of LabelEncoder\n",
    "    def encode_transform(self, cats):\n",
    "        encoded_cats = {}\n",
    "\n",
    "        for cat in cats.columns:\n",
    "            encoded_cats[cat] = self.encoders[cat].transform(cats[cat]) # won't work if cats has missing value\n",
    "\n",
    "        return pd.DataFrame(encoded_cats) #, encoders\n",
    "     \n",
    "\n",
    "    # encode_by_1hot_fit: list of string, pd.DataFrame --> dict of pd.sparseMatrix\n",
    "    # encodes by OneHotEncoder for each column in cat_ind in data\n",
    "    def encode_by_1hot_fit(self, cat_ind, data):\n",
    "        cat_1hot = []\n",
    "\n",
    "        for col in cat_ind:\n",
    "            onehot_coder = OneHotEncoder()\n",
    "            cat_1hot.append(onehot_coder.fit_transform(data[col].values.reshape(-1,1)))\n",
    "            self.Onehot_coders[col] = onehot_coder\n",
    "\n",
    "        return cat_1hot #, Onehot_coders\n",
    "    \n",
    "    # encode_by_1hot: list of string, pd.DataFrame --> dict of pd.sparseMatrix\n",
    "    def encode_by_1hot_transform(self, cat_ind, data):\n",
    "        cat_1hot = []\n",
    "\n",
    "        for col in cat_ind:\n",
    "            cat_1hot.append(self.Onehot_coders[col].transform(data[col].values.reshape(-1,1)))\n",
    "\n",
    "        return cat_1hot #, Onehot_coders\n",
    "    \n",
    "    # add_0_indicators: pd.DataFrame --> void\n",
    "    # for col in ZERO_HEAVY_COLS, change all the zero to the median in data\n",
    "    # then make a new column in data with 1 == this entry was 0 in col and\n",
    "    # 0 == otherwise\n",
    "    # this is used to shift the zero heavy datas to the median,\n",
    "    # in an attempt to correct skewedness\n",
    "    def add_0_indicators(self, data):   \n",
    "        for col in self.ZERO_HEAVY_COLS:\n",
    "            new_col = col + '_zero'\n",
    "            data[new_col] = 1 * (data[col] == 0)\n",
    "\n",
    "            changed_0 = data[col][data[col] > 0].median()\n",
    "            data.loc[data[col]==0, col] = changed_0\n",
    "    \n",
    "    def seperate_train_label_cols(self, data):\n",
    "        cols = data.columns\n",
    "        \n",
    "        if 'SalePrice' in cols:\n",
    "            return cols.drop('SalePrice'), pd.Index(['SalePrice'], dtype=data['SalePrice'].dtype)\n",
    "        else:\n",
    "            return cols, None\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def fit(self, data): \n",
    "        training_cols, label_col = self.seperate_train_label_cols(data)\n",
    "        #print(len(training_cols), len(label_col))\n",
    "        \n",
    "        if label_col != None:\n",
    "            labels = data[label_col]\n",
    "        else:\n",
    "            labels = 1\n",
    "            \n",
    "        #print(labels)\n",
    "        \n",
    "        data = data[training_cols]\n",
    "        \n",
    "        #print(labels)\n",
    "        \n",
    "        # find numeric and categorical columns of data\n",
    "        nums_ind, cat_ind = self.seperate_num_and_cat(data)\n",
    "        \n",
    "        #print(len(nums_ind))\n",
    "        #print(len(cat_ind))\n",
    "        #print(len(nums_ind+cat_ind))\n",
    "\n",
    "        # in numerical data: fill nan by mean\n",
    "        data[nums_ind] = data[nums_ind].fillna(data[nums_ind].median())\n",
    "\n",
    "        # in categorical data: fill nan by 'nan'\n",
    "        data[cat_ind] = data[cat_ind].fillna('UofTMath').astype(str)\n",
    "        #print(data[cat_ind])\n",
    "        \n",
    "        # print(len(data[nums_ind].columns), len(data[cat_ind].columns))\n",
    "        \n",
    "        # change all the zeros to median and make a new column to indicate the appearance of 0\n",
    "        self.add_0_indicators(data)\n",
    "        cat_ind += self.ZERO_HEAVY_COLS_zero\n",
    "        # print(len(data[nums_ind].columns), len(data[cat_ind].columns))\n",
    "        \n",
    "\n",
    "        # scale the numerical columns to 0 mean and 1 standard deviation\n",
    "        self.scaler = MinMaxScaler()\n",
    "        data[nums_ind] = \\\n",
    "            pd.DataFrame(self.scaler.fit_transform(data[nums_ind]), columns=nums_ind)\n",
    "        #print(len(data[nums_ind].columns), len(data[cat_ind].columns))\n",
    "        \n",
    "        # encode categories\n",
    "        # somehow data[cat_ind] = self.encode(data[cat_ind]) produces NaN everywhere\n",
    "        # due to type conversion.\n",
    "        data_cat = self.encode_fit(data[cat_ind])\n",
    "        # print(x)\n",
    "        # data[cat_ind] = x\n",
    "        # print(data[cat_ind])\n",
    "        # print(labels)\n",
    "        # print(len(data[nums_ind].columns), len(data_cat.columns))\n",
    "        \n",
    "        \n",
    "        # 1hot encode\n",
    "        cat_1hot = self.encode_by_1hot_fit(cat_ind, data_cat)\n",
    "        #print(len(cat_1hot))\n",
    "        \n",
    "        # put the numerical dense matrix in sparse format so that we can concatenate it with the 1hot encodings\n",
    "        data_num = sparse.csr_matrix(data[nums_ind].values)\n",
    "        #print(data_num.shape)\n",
    "            \n",
    "        # after clean data, we fit\n",
    "        self.training_data, self.training_label = \\\n",
    "        sparse.hstack([data_num] + cat_1hot), self.preprocess_label(labels)\n",
    "        \n",
    "        self.regressor = BaggingRegressor(base_estimator=GradientBoostingRegressor(min_samples_split=2, # this is default \n",
    "                                                                               max_depth=3 # this is default\n",
    "                                                                              ), \n",
    "                                      n_estimators=10, # default is 10\n",
    "                                      max_features=0.3, # default is all or 1.0\n",
    "                                      n_jobs=-1\n",
    "                                     )\n",
    "        \n",
    "        self.regressor.fit(self.training_data, self.training_label)\n",
    "    \n",
    "    def preprocess_label(self, y):\n",
    "        return np.log(y)\n",
    "    \n",
    "    def transform(self, data):\n",
    "        training_cols, label_col = self.seperate_train_label_cols(data)\n",
    "        #print(len(training_cols), len(label_col))\n",
    "        \n",
    "        if label_col != None:\n",
    "            labels = data[label_col]\n",
    "        else:\n",
    "            labels = 1\n",
    "            \n",
    "        #print(labels)\n",
    "        \n",
    "        data = data[training_cols]\n",
    "        \n",
    "        #print(labels)\n",
    "        \n",
    "        # find numeric and categorical columns of data\n",
    "        nums_ind, cat_ind = self.seperate_num_and_cat(data)\n",
    "        \n",
    "        #print(len(nums_ind))\n",
    "        #print(len(cat_ind))\n",
    "        #print(len(nums_ind+cat_ind))\n",
    "\n",
    "        # in numerical data: fill nan by mean\n",
    "        data[nums_ind] = data[nums_ind].fillna(data[nums_ind].median())\n",
    "\n",
    "        # in categorical data: fill nan by 'nan'\n",
    "        data[cat_ind] = data[cat_ind].fillna('UofTMath').astype(str)\n",
    "        #print(data[cat_ind])\n",
    "        \n",
    "        # print(len(data[nums_ind].columns), len(data[cat_ind].columns))\n",
    "        \n",
    "        # change all the zeros to median and make a new column to indicate the appearance of 0\n",
    "        self.add_0_indicators(data)\n",
    "        cat_ind += self.ZERO_HEAVY_COLS_zero\n",
    "        # print(len(data[nums_ind].columns), len(data[cat_ind].columns))\n",
    "        \n",
    "\n",
    "        # scale the numerical columns to 0 mean and 1 standard deviation\n",
    "        data[nums_ind] = \\\n",
    "            pd.DataFrame(self.scaler.transform(data[nums_ind]), columns=nums_ind)\n",
    "        #print(len(data[nums_ind].columns), len(data[cat_ind].columns))\n",
    "        \n",
    "        # encode categories\n",
    "        # somehow data[cat_ind] = self.encode(data[cat_ind]) produces NaN everywhere\n",
    "        # due to type conversion.\n",
    "        data_cat = self.encode_transform(data[cat_ind])\n",
    "        # print(x)\n",
    "        # data[cat_ind] = x\n",
    "        # print(data[cat_ind])\n",
    "        # print(labels)\n",
    "        # print(len(data[nums_ind].columns), len(data_cat.columns))\n",
    "        \n",
    "        \n",
    "        # 1hot encode\n",
    "        cat_1hot = self.encode_by_1hot_transform(cat_ind, data_cat)\n",
    "        #print(len(cat_1hot))\n",
    "        \n",
    "        # put the numerical dense matrix in sparse format so that we can concatenate it with the 1hot encodings\n",
    "        data_num = sparse.csr_matrix(data[nums_ind].values)\n",
    "        #print(data_num.shape)\n",
    "            \n",
    "        return sparse.hstack([data_num] + cat_1hot), self.preprocess_label(labels)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def postprocess_label(self, y):\n",
    "        return np.exp(y)\n",
    "\n",
    "        \n",
    "    def predict(self, data):\n",
    "        X, _ = self.preprocess_data(data)\n",
    "        \n",
    "        return self.regressor.predict(X)\n",
    "\n",
    "        \n",
    "    def input_data(self, X):\n",
    "        self.training_data = self.preprocess_training_data(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = HousingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: 'CBlock'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36m_encode_python\u001b[1;34m(values, uniques, encode)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mencoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mencoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'CBlock'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-a7977fb52cc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-1790ba189f0a>\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[1;31m# somehow data[cat_ind] = self.encode(data[cat_ind]) produces NaN everywhere\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         \u001b[1;31m# due to type conversion.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m         \u001b[0mdata_cat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcat_ind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m         \u001b[1;31m# print(x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[1;31m# data[cat_ind] = x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-1790ba189f0a>\u001b[0m in \u001b[0;36mencode_transform\u001b[1;34m(self, cats)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcat\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m             \u001b[0mencoded_cats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# won't work if cats has missing value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded_cats\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#, encoders\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    255\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36m_encode\u001b[1;34m(values, uniques, encode)\u001b[0m\n\u001b[0;32m    106\u001b[0m     \"\"\"\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_encode_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_encode_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36m_encode_python\u001b[1;34m(values, uniques, encode)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             raise ValueError(\"y contains previously unseen labels: %s\"\n\u001b[1;32m---> 71\u001b[1;33m                              % str(e))\n\u001b[0m\u001b[0;32m     72\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoded\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: y contains previously unseen labels: 'CBlock'"
     ]
    }
   ],
   "source": [
    "a, _ = x.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
