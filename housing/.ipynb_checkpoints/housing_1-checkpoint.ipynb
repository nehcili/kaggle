{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Getting all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-440e6969c6da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTransformerMixin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRegressorMixin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# numerical feature engineering\n",
    "from scipy.stats import skew\n",
    "#categorical feature engineering\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# FeatureUnion\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import ElasticNet, Lasso\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv').drop(['Id'], axis=1)\n",
    "print(\"Shape of training data:\", train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data imputation/mannual engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None, outlier=False):\n",
    "        # take log of the SalePrice\n",
    "        X['SalePrice'] = np.log(X['SalePrice'])\n",
    "        \n",
    "        # Get rid of Outliers\n",
    "        if outlier:\n",
    "            X = X[X.GrLivArea < 4000]\n",
    "\n",
    "        # Alley : data description says NA means \"no alley access\"\n",
    "        X.loc[:, \"Alley\"] = X.loc[:, \"Alley\"].fillna(\"None\")\n",
    "        # BedroomAbvGr : NA most likely means 0\n",
    "        X.loc[:, \"BedroomAbvGr\"] = X.loc[:, \"BedroomAbvGr\"].fillna(0)\n",
    "        # BsmtQual etc : data description says NA for basement features is \"no basement\"\n",
    "        X.loc[:, \"BsmtQual\"] = X.loc[:, \"BsmtQual\"].fillna(\"No\")\n",
    "        X.loc[:, \"BsmtCond\"] = X.loc[:, \"BsmtCond\"].fillna(\"No\")\n",
    "        X.loc[:, \"BsmtExposure\"] = X.loc[:, \"BsmtExposure\"].fillna(\"No\")\n",
    "        X.loc[:, \"BsmtFinType1\"] = X.loc[:, \"BsmtFinType1\"].fillna(\"No\")\n",
    "        X.loc[:, \"BsmtFinType2\"] = X.loc[:, \"BsmtFinType2\"].fillna(\"No\")\n",
    "        X.loc[:, \"BsmtFullBath\"] = X.loc[:, \"BsmtFullBath\"].fillna(0)\n",
    "        X.loc[:, \"BsmtHalfBath\"] = X.loc[:, \"BsmtHalfBath\"].fillna(0)\n",
    "        X.loc[:, \"BsmtUnfSF\"] = X.loc[:, \"BsmtUnfSF\"].fillna(0)\n",
    "        # CentralAir : NA most likely means No\n",
    "        X.loc[:, \"CentralAir\"] = X.loc[:, \"CentralAir\"].fillna(\"N\")\n",
    "        # Condition : NA most likely means Normal\n",
    "        X.loc[:, \"Condition1\"] = X.loc[:, \"Condition1\"].fillna(\"Norm\")\n",
    "        X.loc[:, \"Condition2\"] = X.loc[:, \"Condition2\"].fillna(\"Norm\")\n",
    "        # EnclosedPorch : NA most likely means no enclosed porch\n",
    "        X.loc[:, \"EnclosedPorch\"] = X.loc[:, \"EnclosedPorch\"].fillna(0)\n",
    "        # External stuff : NA most likely means average\n",
    "        X.loc[:, \"ExterCond\"] = X.loc[:, \"ExterCond\"].fillna(\"TA\")\n",
    "        X.loc[:, \"ExterQual\"] = X.loc[:, \"ExterQual\"].fillna(\"TA\")\n",
    "        # Fence : data description says NA means \"no fence\"\n",
    "        X.loc[:, \"Fence\"] = X.loc[:, \"Fence\"].fillna(\"No\")\n",
    "        # FireplaceQu : data description says NA means \"no fireplace\"\n",
    "        X.loc[:, \"FireplaceQu\"] = X.loc[:, \"FireplaceQu\"].fillna(\"No\")\n",
    "        X.loc[:, \"Fireplaces\"] = X.loc[:, \"Fireplaces\"].fillna(0)\n",
    "        # Functional : data description says NA means typical\n",
    "        X.loc[:, \"Functional\"] = X.loc[:, \"Functional\"].fillna(\"Typ\")\n",
    "        # GarageType etc : data description says NA for garage features is \"no garage\"\n",
    "        X.loc[:, \"GarageType\"] = X.loc[:, \"GarageType\"].fillna(\"No\")\n",
    "        X.loc[:, \"GarageFinish\"] = X.loc[:, \"GarageFinish\"].fillna(\"No\")\n",
    "        X.loc[:, \"GarageQual\"] = X.loc[:, \"GarageQual\"].fillna(\"No\")\n",
    "        X.loc[:, \"GarageCond\"] = X.loc[:, \"GarageCond\"].fillna(\"No\")\n",
    "        X.loc[:, \"GarageArea\"] = X.loc[:, \"GarageArea\"].fillna(0)\n",
    "        X.loc[:, \"GarageCars\"] = X.loc[:, \"GarageCars\"].fillna(0)\n",
    "        # HalfBath : NA most likely means no half baths above grade\n",
    "        X.loc[:, \"HalfBath\"] = X.loc[:, \"HalfBath\"].fillna(0)\n",
    "        # HeatingQC : NA most likely means typical\n",
    "        X.loc[:, \"HeatingQC\"] = X.loc[:, \"HeatingQC\"].fillna(\"TA\")\n",
    "        # KitchenAbvGr : NA most likely means 0\n",
    "        X.loc[:, \"KitchenAbvGr\"] = X.loc[:, \"KitchenAbvGr\"].fillna(0)\n",
    "        # KitchenQual : NA most likely means typical\n",
    "        X.loc[:, \"KitchenQual\"] = X.loc[:, \"KitchenQual\"].fillna(\"TA\")\n",
    "        # LotFrontage : NA most likely means no lot frontage\n",
    "        X.loc[:, \"LotFrontage\"] = X.loc[:, \"LotFrontage\"].fillna(0)\n",
    "        # LotShape : NA most likely means regular\n",
    "        X.loc[:, \"LotShape\"] = X.loc[:, \"LotShape\"].fillna(\"Reg\")\n",
    "        # MasVnrType : NA most likely means no veneer\n",
    "        X.loc[:, \"MasVnrType\"] = X.loc[:, \"MasVnrType\"].fillna(\"None\")\n",
    "        X.loc[:, \"MasVnrArea\"] = X.loc[:, \"MasVnrArea\"].fillna(0)\n",
    "        # MiscFeature : data description says NA means \"no misc feature\"\n",
    "        X.loc[:, \"MiscFeature\"] = X.loc[:, \"MiscFeature\"].fillna(\"No\")\n",
    "        X.loc[:, \"MiscVal\"] = X.loc[:, \"MiscVal\"].fillna(0)\n",
    "        # OpenPorchSF : NA most likely means no open porch\n",
    "        X.loc[:, \"OpenPorchSF\"] = X.loc[:, \"OpenPorchSF\"].fillna(0)\n",
    "        # PavedDrive : NA most likely means not paved\n",
    "        X.loc[:, \"PavedDrive\"] = X.loc[:, \"PavedDrive\"].fillna(\"N\")\n",
    "        # PoolQC : data description says NA means \"no pool\"\n",
    "        X.loc[:, \"PoolQC\"] = X.loc[:, \"PoolQC\"].fillna(\"No\")\n",
    "        X.loc[:, \"PoolArea\"] = X.loc[:, \"PoolArea\"].fillna(0)\n",
    "        # SaleCondition : NA most likely means normal sale\n",
    "        X.loc[:, \"SaleCondition\"] = X.loc[:, \"SaleCondition\"].fillna(\"Normal\")\n",
    "        # ScreenPorch : NA most likely means no screen porch\n",
    "        X.loc[:, \"ScreenPorch\"] = X.loc[:, \"ScreenPorch\"].fillna(0)\n",
    "        # TotRmsAbvGrd : NA most likely means 0\n",
    "        X.loc[:, \"TotRmsAbvGrd\"] = X.loc[:, \"TotRmsAbvGrd\"].fillna(0)\n",
    "        # Utilities : NA most likely means all public utilities\n",
    "        X.loc[:, \"Utilities\"] = X.loc[:, \"Utilities\"].fillna(\"AllPub\")\n",
    "        # WoodDeckSF : NA most likely means no wood deck\n",
    "        X.loc[:, \"WoodDeckSF\"] = X.loc[:, \"WoodDeckSF\"].fillna(0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Some numerical features are actually really categories\n",
    "        X = X.replace({\"MSSubClass\" : {20 : \"SC20\", 30 : \"SC30\", 40 : \"SC40\", 45 : \"SC45\", \n",
    "                                       50 : \"SC50\", 60 : \"SC60\", 70 : \"SC70\", 75 : \"SC75\", \n",
    "                                       80 : \"SC80\", 85 : \"SC85\", 90 : \"SC90\", 120 : \"SC120\", \n",
    "                                       150 : \"nan\", 160 : \"SC160\", 180 : \"SC180\", 190 : \"SC190\"},\n",
    "                       \"MoSold\" : {1 : \"Jan\", 2 : \"Feb\", 3 : \"Mar\", 4 : \"Apr\", 5 : \"May\", 6 : \"Jun\",\n",
    "                                   7 : \"Jul\", 8 : \"Aug\", 9 : \"Sep\", 10 : \"Oct\", 11 : \"Nov\", 12 : \"Dec\"}\n",
    "                      })\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Encode some categorical features as ordered numbers when there is information in the order\n",
    "        X = X.replace({\"Alley\" : {\"Grvl\" : 1, \"Pave\" : 2},\n",
    "                       \"BsmtCond\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"BsmtExposure\" : {\"No\" : 0, \"Mn\" : 1, \"Av\": 2, \"Gd\" : 3},\n",
    "                       \"BsmtFinType1\" : {\"No\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4, \n",
    "                                         \"ALQ\" : 5, \"GLQ\" : 6},\n",
    "                       \"BsmtFinType2\" : {\"No\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4, \n",
    "                                         \"ALQ\" : 5, \"GLQ\" : 6},\n",
    "                       \"BsmtQual\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"ExterCond\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n",
    "                       \"ExterQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n",
    "                       \"FireplaceQu\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"Functional\" : {\"Sal\" : 1, \"Sev\" : 2, \"Maj2\" : 3, \"Maj1\" : 4, \"Mod\": 5, \n",
    "                                       \"Min2\" : 6, \"Min1\" : 7, \"Typ\" : 8},\n",
    "                       \"GarageCond\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"GarageQual\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"HeatingQC\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"KitchenQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"LandSlope\" : {\"Sev\" : 1, \"Mod\" : 2, \"Gtl\" : 3},\n",
    "                       \"LotShape\" : {\"IR3\" : 1, \"IR2\" : 2, \"IR1\" : 3, \"Reg\" : 4},\n",
    "                       \"PavedDrive\" : {\"N\" : 0, \"P\" : 1, \"Y\" : 2},\n",
    "                       \"PoolQC\" : {\"No\" : 0, \"Fa\" : 1, \"TA\" : 2, \"Gd\" : 3, \"Ex\" : 4},\n",
    "                       \"Street\" : {\"Grvl\" : 1, \"Pave\" : 2},\n",
    "                       \"Utilities\" : {\"ELO\" : 1, \"NoSeWa\" : 2, \"NoSewr\" : 3, \"AllPub\" : 4}}\n",
    "                     )\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Total number of bathrooms\n",
    "        X[\"TotalBath\"] = X[\"BsmtFullBath\"] + (0.5 * X[\"BsmtHalfBath\"]) + \\\n",
    "        X[\"FullBath\"] + (0.5 * X[\"HalfBath\"])\n",
    "        # Total number of bathrooms\n",
    "        X[\"TotalBath\"] = X[\"BsmtFullBath\"] + (0.5 * X[\"BsmtHalfBath\"]) + \\\n",
    "        X[\"FullBath\"] + (0.5 * X[\"HalfBath\"])\n",
    "        # Total SF for house (incl. basement)\n",
    "        X[\"AllSF\"] = X[\"GrLivArea\"] + X[\"TotalBsmtSF\"]\n",
    "        # Total SF for 1st + 2nd floors\n",
    "        X[\"AllFlrsSF\"] = X[\"1stFlrSF\"] + X[\"2ndFlrSF\"]\n",
    "        # Total SF for porch\n",
    "        X[\"AllPorchSF\"] = X[\"OpenPorchSF\"] + X[\"EnclosedPorch\"] + \\\n",
    "        X[\"3SsnPorch\"] + X[\"ScreenPorch\"]\n",
    "        # Has masonry veneer or not\n",
    "        X[\"HasMasVnr\"] = X.MasVnrType.replace({\"BrkCmn\" : 1, \"BrkFace\" : 1, \"CBlock\" : 1, \n",
    "                                                       \"Stone\" : 1, \"None\" : 0})\n",
    "        # House completed before sale or not\n",
    "        X[\"BoughtOffPlan\"] = X.SaleCondition.replace({\"Abnorml\" : 0, \"Alloca\" : 0, \"AdjLand\" : 0, \n",
    "                                                              \"Family\" : 0, \"Normal\" : 0, \"Partial\" : 1})\n",
    "        \n",
    "        #shuffle_index = np.random.permutation(X.shape[1], self.rd_state)\n",
    "        \n",
    "        return X #[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Seperating Numerical and Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv').drop(['Id'], axis=1)\n",
    "print(\"Shape of training data:\", train.shape)\n",
    "\n",
    "P = Preprocessor()\n",
    "train = P.transform(train, outlier=False)\n",
    "\n",
    "# Differentiate numerical features (minus the target) and categorical features\n",
    "categorical_features = train.select_dtypes(include = [\"object\"]).columns\n",
    "numerical_features = train.select_dtypes(exclude = [\"object\"]).columns\n",
    "\n",
    "print(\"Numerical features : \" + str(len(numerical_features)))\n",
    "print(\"Categorical features : \" + str(len(categorical_features)))\n",
    "print(\"Shape of training data post processing:\", train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go from pd.dataFrame to np.array\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names, method=None, dtype='array'):\n",
    "        self.method = method\n",
    "        self.attribute_names = attribute_names\n",
    "        self.dtype = dtype\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        if self.method == 'all':\n",
    "            attribute_names = X.columns\n",
    "        elif self.method == 'all-drop':\n",
    "            attribute_names = X.columns.drop(['SalePrice'])\n",
    "        elif self.method == 'drop':\n",
    "            attribute_names = self.attribute_names.columns.drop(['SalePrice'])\n",
    "        else:\n",
    "            attribute_names = self.attribute_names\n",
    "            \n",
    "        if self.dtype == 'array':\n",
    "            return X[attribute_names].values\n",
    "        else:\n",
    "            return X[attribute_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Numerical Features Engineering (Everything is in np.array)\n",
    "### 2.3.1 Fill NA's in numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FillNAN(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, *args, **kwargs):    \n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.median = X.median()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle remaining missing values for numerical features by using median as replacement\n",
    "X_train_num = train[numerical_features]\n",
    "F = FillNAN()\n",
    "X_train_num = F.fit_transform(X_train_num)\n",
    "\n",
    "print(\"Remaining NAs for numerical features in train : \" + str(X_train_num.isnull().values.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Add top k quadratic + top k cubic + top k square roots + top k inverses; k=20 default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNonlin(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, k=10, *args, **kwargs):\n",
    "        self.top_indices = [] # order is [original, quad, cube, sqrt, invr, quad_diag, cube_diag]\n",
    "        self.k = k\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        #X = X.copy()\n",
    "        corr = np.abs(X.corr())\n",
    "        corr.sort_values([\"SalePrice\"], ascending = False, inplace = True)\n",
    "        self.top_indices.append(corr[\"SalePrice\"].index)\n",
    "        \n",
    "        \n",
    "        y = X[['SalePrice']]\n",
    "        X = X.drop(['SalePrice'], axis=1)\n",
    "        cols = X.columns\n",
    "        \n",
    "        \n",
    "        # sqrt and inverse\n",
    "        sqrt = np.sqrt(np.abs(X))\n",
    "        invr = 1/(1+X)\n",
    "        \n",
    "        # quadratic computation with all possible features in X\n",
    "        quad = pd.DataFrame()\n",
    "        n = len(X.columns)\n",
    "        for i in range(n):\n",
    "            for j in range(i, n):\n",
    "                quad[cols[i] + '-' + cols[j]] = X[cols[i]] * X[cols[j]]\n",
    "        \n",
    "        #print('hi2')\n",
    "        # cubic computation, only compute cubic terms from top 10 original features\n",
    "        cube = pd.DataFrame()\n",
    "        #print(self.top_indices[0])\n",
    "        #print(self.top_indices[0])\n",
    "        #print(X.columns)\n",
    "        X = X[self.top_indices[0][1:self.k+1]]\n",
    "        cols = X.columns\n",
    "        n = len(X.columns)\n",
    "        \n",
    "        #print('hi')\n",
    "        for i in range(n):\n",
    "            for j in range(i, n):\n",
    "                for k in range(j, n):\n",
    "                    cube[cols[i] + '-' + cols[j] + '-' + cols[k]] = X[cols[i]] * X[cols[j]] * X[cols[k]]\n",
    "        \n",
    "        \n",
    "        for data in [quad, cube, sqrt, invr]:\n",
    "            data = pd.concat([data, y], axis=1)\n",
    "            #print(data.columns)\n",
    "            corr = np.abs(data.corr())\n",
    "            corr.sort_values([\"SalePrice\"], ascending = False, inplace = True)\n",
    "            self.top_indices.append(corr[\"SalePrice\"].index[1:self.k+1])\n",
    "        \n",
    "        \n",
    "        return self\n",
    "        \n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        quad = pd.DataFrame()\n",
    "        cube = pd.DataFrame()\n",
    "        sqrt = np.sqrt(X[self.top_indices[3]])\n",
    "        sqrt.columns = sqrt.columns + '-sqrt'\n",
    "        invr = 1/(1+X[self.top_indices[4]])\n",
    "        invr.columns = invr.columns + '-invr'\n",
    "\n",
    "        \n",
    "        for ind in self.top_indices[1]:\n",
    "            a, b = ind.split('-')\n",
    "            quad[a + '-' + b] = X[a] * X[b]\n",
    "        \n",
    "        for ind in self.top_indices[2]:\n",
    "            a, b, c = ind.split('-')\n",
    "            cube[a + '-' + b + '-' + c] = X[a] * X[b] * X[c]\n",
    "        \n",
    "        #print('X.columns', X.columns)\n",
    "        #print(X.columns[self.k_original+1])\n",
    "        \n",
    "        \n",
    "        return pd.concat([X, quad, cube, sqrt, invr], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = AddNonlin()\n",
    "t = N.fit_transform(train[numerical_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Skewness Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unskew(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.skewness = X.apply(lambda x: skew(x))\n",
    "        self.skewness = self.skewness[abs(self.skewness) > 0.5]\n",
    "        self.skewed_features = self.skewness.index\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X[self.skewed_features] = np.log1p(X[self.skewed_features])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.X Numerical Feature Engineering Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feature_eng_pipeline = Pipeline([\n",
    "    ('selec_num', DataFrameSelector(numerical_features, dtype='df')), # input and output types = dataFrame\n",
    "    ('nonlinearity', AddNonlin(k=20)), # this need target to fit cann't drop SalePrice yet\n",
    "    ('fillnan', FillNAN()), # input and output types = dataFrame\n",
    "    ('drop_SalePrice', DataFrameSelector(numerical_features, method='all-drop', dtype='df')), \n",
    "    # input and output types = dataFrame\n",
    "    # SalePrice is dropped\n",
    "    # everything \n",
    "    ('unskew', Unskew()),\n",
    "    #('selector_array', DataFrameSelector(numerical_features, method='all', dtype='array')),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = num_feature_eng_pipeline.fit_transform(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Categorical Features Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 Fill missing values by most frequent values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FillCatNan(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.imputer = SimpleImputer(missing_values='nan', strategy='most_frequent')\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.imputer.fit(X.astype(str))\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return self.imputer.transform(X.astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLabelEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.encoders = []\n",
    "    \n",
    "    def fit(self, x, y=0):\n",
    "        X = x.transpose()\n",
    "        self.encoders = []\n",
    "        \n",
    "        \n",
    "        for i in range(X.shape[0]):\n",
    "            l = LabelEncoder()\n",
    "            l.fit(X[i])\n",
    "            self.encoders.append(l)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def transform(self, x, y=0):\n",
    "        X = x.transpose()\n",
    "        for i, l in enumerate(self.encoders):\n",
    "            #print(i)\n",
    "            X[i] = l.transform(X[i])\n",
    "        \n",
    "        return X.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.3 OneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyOneHotEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.onehot = OneHotEncoder()\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.onehot.fit(X)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return self.onehot.transform(X).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.X Categorical Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feature_eng_pipeline = Pipeline([\n",
    "    ('selec_cat', DataFrameSelector(categorical_features, dtype='df')), # i/o type = df\n",
    "    ('fill_by_mode', FillCatNan()), # output is array\n",
    "    ('encoder', MyLabelEncoder()),\n",
    "    ('onehot', MyOneHotEncoder()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c = cat_feature_eng_pipeline.fit_transform(train)\n",
    "#c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "    (\"num_feature_eng_pipeline\", num_feature_eng_pipeline),\n",
    "    (\"cat_feature_eng_pipeline\", cat_feature_eng_pipeline),\n",
    "])\n",
    "\n",
    "housing_prepared = full_pipeline.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prepared.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Test Case Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test.csv').drop(['Id'], axis=1)\n",
    "test = pd.concat([test, pd.DataFrame({'SalePrice' : [0]})]).iloc[:-1,:]\n",
    "test['SalePrice'] = 1\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = P.transform(test, outlier=False)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test = full_pipeline.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['SalePrice'].values\n",
    "\n",
    "shuffle_index = np.random.permutation(y.shape[0])\n",
    "housing_prepared, y = housing_prepared[shuffle_index], y[shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(model, cv=10):\n",
    "    reg_score = cross_val_score(model, housing_prepared, y, scoring='neg_mean_squared_error', cv=cv)\n",
    "    s = np.sqrt(-reg_score)\n",
    "    print('scores:', s)\n",
    "    print('mean score:', s.mean())\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(model):\n",
    "    model.fit(housing_prepared, y)\n",
    "    ypred = np.exp(model.predict(test))\n",
    "    Id = list(range(1461, 2920))\n",
    "    output = pd.DataFrame({'Id': Id, 'SalePrice' : ypred})\n",
    "    with open('submit.csv', 'w') as f:\n",
    "        f.write(output.to_csv(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg_scores = score_model(LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predict(LinearRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 l1 Regularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = LassoCV(alphas=[0.0001, 0.0002, 0.0004, 0.0006, 0.001, 0.002, \n",
    "                          0.004, 0.006, 0.01, 0.02, 0.04, 0.06, 0.1, 0.5, 1, 2,5,10], cv=10)\n",
    "lasso_reg_sores = score_model(lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_predict(lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 l2 Regularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = RidgeCV(alphas=[0.01, 0.02, 0.04, 0.06, 0.1, 0.5, 1, 2,5,10, 20, 22, 24, 26, 28, 30, 32], cv=10)\n",
    "ridge_reg_sores = score_model(ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4 l1 and l2 Regularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.0001, 0.0002, 0.0004, 0.0006, 0.0008, 0.001, 0.002, \n",
    "                          0.004, 0.006, 0.008, 0.01, 0.02, 0.04, 0.06, 0.08, 0.1, 0.5, 0.8, 0.9, 0.95, 1, 1.1, 2,5,10] \n",
    "elasticNet = ElasticNetCV(l1_ratio = [0.1, 0.3, 0.5, 0.6, 0.7, 0.8, 0.85, 0.9, 0.95, 1],\n",
    "                          alphas = alphas, \n",
    "                          max_iter = 50000, cv = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticNet_score = score_model(elasticNet, cv=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.5 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg_scores = score_model(RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.6 Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)\n",
    "xgb_reg_scores = score_model(xgb_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1.7 Stacked Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now use a more sophisticated stacking approach.\n",
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        #print(out_of_fold_predictions)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initalize models\n",
    "\n",
    "KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0006, random_state=1))\n",
    "\n",
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0006, l1_ratio=.9, random_state=3))\n",
    "\n",
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "\n",
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)\n",
    "\n",
    "stacked_averaged_models = StackingAveragedModels(base_models = (ENet, GBoost, KRR, lasso, RandomForestRegressor(), RidgeCV),\n",
    "                                                 meta_model = lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacked_avg_score = score_model(stacked_averaged_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predict(stacked_averaged_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
