{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Getting all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# numerical feature engineering\n",
    "from scipy.stats import skew\n",
    "#categorical feature engineering\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# FeatureUnion\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: (1460, 80)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/train.csv').drop(['Id'], axis=1)\n",
    "print(\"Shape of training data:\", train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data imputation/mannual engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None, outlier=False):\n",
    "        # take log of the SalePrice\n",
    "        X['SalePrice'] = np.log(X['SalePrice'])\n",
    "        \n",
    "        # Get rid of Outliers\n",
    "        if outlier:\n",
    "            X = X[X.GrLivArea < 4000]\n",
    "\n",
    "        # Alley : data description says NA means \"no alley access\"\n",
    "        X.loc[:, \"Alley\"] = X.loc[:, \"Alley\"].fillna(\"None\")\n",
    "        # BedroomAbvGr : NA most likely means 0\n",
    "        X.loc[:, \"BedroomAbvGr\"] = X.loc[:, \"BedroomAbvGr\"].fillna(0)\n",
    "        # BsmtQual etc : data description says NA for basement features is \"no basement\"\n",
    "        X.loc[:, \"BsmtQual\"] = X.loc[:, \"BsmtQual\"].fillna(\"No\")\n",
    "        X.loc[:, \"BsmtCond\"] = X.loc[:, \"BsmtCond\"].fillna(\"No\")\n",
    "        X.loc[:, \"BsmtExposure\"] = X.loc[:, \"BsmtExposure\"].fillna(\"No\")\n",
    "        X.loc[:, \"BsmtFinType1\"] = X.loc[:, \"BsmtFinType1\"].fillna(\"No\")\n",
    "        X.loc[:, \"BsmtFinType2\"] = X.loc[:, \"BsmtFinType2\"].fillna(\"No\")\n",
    "        X.loc[:, \"BsmtFullBath\"] = X.loc[:, \"BsmtFullBath\"].fillna(0)\n",
    "        X.loc[:, \"BsmtHalfBath\"] = X.loc[:, \"BsmtHalfBath\"].fillna(0)\n",
    "        X.loc[:, \"BsmtUnfSF\"] = X.loc[:, \"BsmtUnfSF\"].fillna(0)\n",
    "        # CentralAir : NA most likely means No\n",
    "        X.loc[:, \"CentralAir\"] = X.loc[:, \"CentralAir\"].fillna(\"N\")\n",
    "        # Condition : NA most likely means Normal\n",
    "        X.loc[:, \"Condition1\"] = X.loc[:, \"Condition1\"].fillna(\"Norm\")\n",
    "        X.loc[:, \"Condition2\"] = X.loc[:, \"Condition2\"].fillna(\"Norm\")\n",
    "        # EnclosedPorch : NA most likely means no enclosed porch\n",
    "        X.loc[:, \"EnclosedPorch\"] = X.loc[:, \"EnclosedPorch\"].fillna(0)\n",
    "        # External stuff : NA most likely means average\n",
    "        X.loc[:, \"ExterCond\"] = X.loc[:, \"ExterCond\"].fillna(\"TA\")\n",
    "        X.loc[:, \"ExterQual\"] = X.loc[:, \"ExterQual\"].fillna(\"TA\")\n",
    "        # Fence : data description says NA means \"no fence\"\n",
    "        X.loc[:, \"Fence\"] = X.loc[:, \"Fence\"].fillna(\"No\")\n",
    "        # FireplaceQu : data description says NA means \"no fireplace\"\n",
    "        X.loc[:, \"FireplaceQu\"] = X.loc[:, \"FireplaceQu\"].fillna(\"No\")\n",
    "        X.loc[:, \"Fireplaces\"] = X.loc[:, \"Fireplaces\"].fillna(0)\n",
    "        # Functional : data description says NA means typical\n",
    "        X.loc[:, \"Functional\"] = X.loc[:, \"Functional\"].fillna(\"Typ\")\n",
    "        # GarageType etc : data description says NA for garage features is \"no garage\"\n",
    "        X.loc[:, \"GarageType\"] = X.loc[:, \"GarageType\"].fillna(\"No\")\n",
    "        X.loc[:, \"GarageFinish\"] = X.loc[:, \"GarageFinish\"].fillna(\"No\")\n",
    "        X.loc[:, \"GarageQual\"] = X.loc[:, \"GarageQual\"].fillna(\"No\")\n",
    "        X.loc[:, \"GarageCond\"] = X.loc[:, \"GarageCond\"].fillna(\"No\")\n",
    "        X.loc[:, \"GarageArea\"] = X.loc[:, \"GarageArea\"].fillna(0)\n",
    "        X.loc[:, \"GarageCars\"] = X.loc[:, \"GarageCars\"].fillna(0)\n",
    "        # HalfBath : NA most likely means no half baths above grade\n",
    "        X.loc[:, \"HalfBath\"] = X.loc[:, \"HalfBath\"].fillna(0)\n",
    "        # HeatingQC : NA most likely means typical\n",
    "        X.loc[:, \"HeatingQC\"] = X.loc[:, \"HeatingQC\"].fillna(\"TA\")\n",
    "        # KitchenAbvGr : NA most likely means 0\n",
    "        X.loc[:, \"KitchenAbvGr\"] = X.loc[:, \"KitchenAbvGr\"].fillna(0)\n",
    "        # KitchenQual : NA most likely means typical\n",
    "        X.loc[:, \"KitchenQual\"] = X.loc[:, \"KitchenQual\"].fillna(\"TA\")\n",
    "        # LotFrontage : NA most likely means no lot frontage\n",
    "        X.loc[:, \"LotFrontage\"] = X.loc[:, \"LotFrontage\"].fillna(0)\n",
    "        # LotShape : NA most likely means regular\n",
    "        X.loc[:, \"LotShape\"] = X.loc[:, \"LotShape\"].fillna(\"Reg\")\n",
    "        # MasVnrType : NA most likely means no veneer\n",
    "        X.loc[:, \"MasVnrType\"] = X.loc[:, \"MasVnrType\"].fillna(\"None\")\n",
    "        X.loc[:, \"MasVnrArea\"] = X.loc[:, \"MasVnrArea\"].fillna(0)\n",
    "        # MiscFeature : data description says NA means \"no misc feature\"\n",
    "        X.loc[:, \"MiscFeature\"] = X.loc[:, \"MiscFeature\"].fillna(\"No\")\n",
    "        X.loc[:, \"MiscVal\"] = X.loc[:, \"MiscVal\"].fillna(0)\n",
    "        # OpenPorchSF : NA most likely means no open porch\n",
    "        X.loc[:, \"OpenPorchSF\"] = X.loc[:, \"OpenPorchSF\"].fillna(0)\n",
    "        # PavedDrive : NA most likely means not paved\n",
    "        X.loc[:, \"PavedDrive\"] = X.loc[:, \"PavedDrive\"].fillna(\"N\")\n",
    "        # PoolQC : data description says NA means \"no pool\"\n",
    "        X.loc[:, \"PoolQC\"] = X.loc[:, \"PoolQC\"].fillna(\"No\")\n",
    "        X.loc[:, \"PoolArea\"] = X.loc[:, \"PoolArea\"].fillna(0)\n",
    "        # SaleCondition : NA most likely means normal sale\n",
    "        X.loc[:, \"SaleCondition\"] = X.loc[:, \"SaleCondition\"].fillna(\"Normal\")\n",
    "        # ScreenPorch : NA most likely means no screen porch\n",
    "        X.loc[:, \"ScreenPorch\"] = X.loc[:, \"ScreenPorch\"].fillna(0)\n",
    "        # TotRmsAbvGrd : NA most likely means 0\n",
    "        X.loc[:, \"TotRmsAbvGrd\"] = X.loc[:, \"TotRmsAbvGrd\"].fillna(0)\n",
    "        # Utilities : NA most likely means all public utilities\n",
    "        X.loc[:, \"Utilities\"] = X.loc[:, \"Utilities\"].fillna(\"AllPub\")\n",
    "        # WoodDeckSF : NA most likely means no wood deck\n",
    "        X.loc[:, \"WoodDeckSF\"] = X.loc[:, \"WoodDeckSF\"].fillna(0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Some numerical features are actually really categories\n",
    "        X = X.replace({\"MSSubClass\" : {20 : \"SC20\", 30 : \"SC30\", 40 : \"SC40\", 45 : \"SC45\", \n",
    "                                       50 : \"SC50\", 60 : \"SC60\", 70 : \"SC70\", 75 : \"SC75\", \n",
    "                                       80 : \"SC80\", 85 : \"SC85\", 90 : \"SC90\", 120 : \"SC120\", \n",
    "                                       150 : \"nan\", 160 : \"SC160\", 180 : \"SC180\", 190 : \"SC190\"},\n",
    "                       \"MoSold\" : {1 : \"Jan\", 2 : \"Feb\", 3 : \"Mar\", 4 : \"Apr\", 5 : \"May\", 6 : \"Jun\",\n",
    "                                   7 : \"Jul\", 8 : \"Aug\", 9 : \"Sep\", 10 : \"Oct\", 11 : \"Nov\", 12 : \"Dec\"}\n",
    "                      })\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Encode some categorical features as ordered numbers when there is information in the order\n",
    "        X = X.replace({\"Alley\" : {\"Grvl\" : 1, \"Pave\" : 2},\n",
    "                       \"BsmtCond\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"BsmtExposure\" : {\"No\" : 0, \"Mn\" : 1, \"Av\": 2, \"Gd\" : 3},\n",
    "                       \"BsmtFinType1\" : {\"No\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4, \n",
    "                                         \"ALQ\" : 5, \"GLQ\" : 6},\n",
    "                       \"BsmtFinType2\" : {\"No\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4, \n",
    "                                         \"ALQ\" : 5, \"GLQ\" : 6},\n",
    "                       \"BsmtQual\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"ExterCond\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n",
    "                       \"ExterQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n",
    "                       \"FireplaceQu\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"Functional\" : {\"Sal\" : 1, \"Sev\" : 2, \"Maj2\" : 3, \"Maj1\" : 4, \"Mod\": 5, \n",
    "                                       \"Min2\" : 6, \"Min1\" : 7, \"Typ\" : 8},\n",
    "                       \"GarageCond\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"GarageQual\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"HeatingQC\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"KitchenQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"LandSlope\" : {\"Sev\" : 1, \"Mod\" : 2, \"Gtl\" : 3},\n",
    "                       \"LotShape\" : {\"IR3\" : 1, \"IR2\" : 2, \"IR1\" : 3, \"Reg\" : 4},\n",
    "                       \"PavedDrive\" : {\"N\" : 0, \"P\" : 1, \"Y\" : 2},\n",
    "                       \"PoolQC\" : {\"No\" : 0, \"Fa\" : 1, \"TA\" : 2, \"Gd\" : 3, \"Ex\" : 4},\n",
    "                       \"Street\" : {\"Grvl\" : 1, \"Pave\" : 2},\n",
    "                       \"Utilities\" : {\"ELO\" : 1, \"NoSeWa\" : 2, \"NoSewr\" : 3, \"AllPub\" : 4}}\n",
    "                     )\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Total number of bathrooms\n",
    "        X[\"TotalBath\"] = X[\"BsmtFullBath\"] + (0.5 * X[\"BsmtHalfBath\"]) + \\\n",
    "        X[\"FullBath\"] + (0.5 * X[\"HalfBath\"])\n",
    "        # Total number of bathrooms\n",
    "        X[\"TotalBath\"] = X[\"BsmtFullBath\"] + (0.5 * X[\"BsmtHalfBath\"]) + \\\n",
    "        X[\"FullBath\"] + (0.5 * X[\"HalfBath\"])\n",
    "        # Total SF for house (incl. basement)\n",
    "        X[\"AllSF\"] = X[\"GrLivArea\"] + X[\"TotalBsmtSF\"]\n",
    "        # Total SF for 1st + 2nd floors\n",
    "        X[\"AllFlrsSF\"] = X[\"1stFlrSF\"] + X[\"2ndFlrSF\"]\n",
    "        # Total SF for porch\n",
    "        X[\"AllPorchSF\"] = X[\"OpenPorchSF\"] + X[\"EnclosedPorch\"] + \\\n",
    "        X[\"3SsnPorch\"] + X[\"ScreenPorch\"]\n",
    "        # Has masonry veneer or not\n",
    "        X[\"HasMasVnr\"] = X.MasVnrType.replace({\"BrkCmn\" : 1, \"BrkFace\" : 1, \"CBlock\" : 1, \n",
    "                                                       \"Stone\" : 1, \"None\" : 0})\n",
    "        # House completed before sale or not\n",
    "        X[\"BoughtOffPlan\"] = X.SaleCondition.replace({\"Abnorml\" : 0, \"Alloca\" : 0, \"AdjLand\" : 0, \n",
    "                                                              \"Family\" : 0, \"Normal\" : 0, \"Partial\" : 1})\n",
    "        \n",
    "        #shuffle_index = np.random.permutation(X.shape[1], self.rd_state)\n",
    "        \n",
    "        return X #[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Seperating Numerical and Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: (1460, 80)\n",
      "Numerical features : 60\n",
      "Categorical features : 26\n",
      "Shape of training data post processing: (1460, 86)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/train.csv').drop(['Id'], axis=1)\n",
    "print(\"Shape of training data:\", train.shape)\n",
    "\n",
    "P = Preprocessor()\n",
    "train = P.transform(train, outlier=False)\n",
    "\n",
    "# Differentiate numerical features (minus the target) and categorical features\n",
    "categorical_features = train.select_dtypes(include = [\"object\"]).columns\n",
    "numerical_features = train.select_dtypes(exclude = [\"object\"]).columns\n",
    "\n",
    "print(\"Numerical features : \" + str(len(numerical_features)))\n",
    "print(\"Categorical features : \" + str(len(categorical_features)))\n",
    "print(\"Shape of training data post processing:\", train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go from pd.dataFrame to np.array\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names, method=None, dtype='array'):\n",
    "        self.method = method\n",
    "        self.attribute_names = attribute_names\n",
    "        self.dtype = dtype\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        if self.method == 'all':\n",
    "            attribute_names = X.columns\n",
    "        elif self.method == 'all-drop':\n",
    "            attribute_names = X.columns.drop(['SalePrice'])\n",
    "        elif self.method == 'drop':\n",
    "            attribute_names = self.attribute_names.columns.drop(['SalePrice'])\n",
    "        else:\n",
    "            attribute_names = self.attribute_names\n",
    "            \n",
    "        if self.dtype == 'array':\n",
    "            return X[attribute_names].values\n",
    "        else:\n",
    "            return X[attribute_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Numerical Features Engineering (Everything is in np.array)\n",
    "### 2.3.1 Fill NA's in numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FillNAN(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, *args, **kwargs):    \n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.median = X.median()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining NAs for numerical features in train : 0\n"
     ]
    }
   ],
   "source": [
    "# Handle remaining missing values for numerical features by using median as replacement\n",
    "X_train_num = train[numerical_features]\n",
    "F = FillNAN()\n",
    "X_train_num = F.fit_transform(X_train_num)\n",
    "\n",
    "print(\"Remaining NAs for numerical features in train : \" + str(X_train_num.isnull().values.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Add top k quadratic + top k cubic + top k square roots + top k inverses; k=20 default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNonlin(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, k=10, *args, **kwargs):\n",
    "        self.top_indices = [] # order is [original, quad, cube, sqrt, invr, quad_diag, cube_diag]\n",
    "        self.k = k\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        #X = X.copy()\n",
    "        corr = np.abs(X.corr())\n",
    "        corr.sort_values([\"SalePrice\"], ascending = False, inplace = True)\n",
    "        self.top_indices.append(corr[\"SalePrice\"].index)\n",
    "        \n",
    "        \n",
    "        y = X[['SalePrice']]\n",
    "        X = X.drop(['SalePrice'], axis=1)\n",
    "        cols = X.columns\n",
    "        \n",
    "        \n",
    "        # sqrt and inverse\n",
    "        sqrt = np.sqrt(np.abs(X))\n",
    "        invr = 1/(1+X)\n",
    "        \n",
    "        # quadratic computation with all possible features in X\n",
    "        quad = pd.DataFrame()\n",
    "        n = len(X.columns)\n",
    "        for i in range(n):\n",
    "            for j in range(i, n):\n",
    "                quad[cols[i] + '-' + cols[j]] = X[cols[i]] * X[cols[j]]\n",
    "        \n",
    "        #print('hi2')\n",
    "        # cubic computation, only compute cubic terms from top 10 original features\n",
    "        cube = pd.DataFrame()\n",
    "        #print(self.top_indices[0])\n",
    "        #print(self.top_indices[0])\n",
    "        #print(X.columns)\n",
    "        X = X[self.top_indices[0][1:self.k+1]]\n",
    "        cols = X.columns\n",
    "        n = len(X.columns)\n",
    "        \n",
    "        #print('hi')\n",
    "        for i in range(n):\n",
    "            for j in range(i, n):\n",
    "                for k in range(j, n):\n",
    "                    cube[cols[i] + '-' + cols[j] + '-' + cols[k]] = X[cols[i]] * X[cols[j]] * X[cols[k]]\n",
    "        \n",
    "        \n",
    "        for data in [quad, cube, sqrt, invr]:\n",
    "            data = pd.concat([data, y], axis=1)\n",
    "            #print(data.columns)\n",
    "            corr = np.abs(data.corr())\n",
    "            corr.sort_values([\"SalePrice\"], ascending = False, inplace = True)\n",
    "            self.top_indices.append(corr[\"SalePrice\"].index[1:self.k+1])\n",
    "        \n",
    "        \n",
    "        return self\n",
    "        \n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        quad = pd.DataFrame()\n",
    "        cube = pd.DataFrame()\n",
    "        sqrt = np.sqrt(X[self.top_indices[3]])\n",
    "        sqrt.columns = sqrt.columns + '-sqrt'\n",
    "        invr = 1/(1+X[self.top_indices[4]])\n",
    "        invr.columns = invr.columns + '-invr'\n",
    "\n",
    "        \n",
    "        for ind in self.top_indices[1]:\n",
    "            a, b = ind.split('-')\n",
    "            quad[a + '-' + b] = X[a] * X[b]\n",
    "        \n",
    "        for ind in self.top_indices[2]:\n",
    "            a, b, c = ind.split('-')\n",
    "            cube[a + '-' + b + '-' + c] = X[a] * X[b] * X[c]\n",
    "        \n",
    "        #print('X.columns', X.columns)\n",
    "        #print(X.columns[self.k_original+1])\n",
    "        \n",
    "        \n",
    "        return pd.concat([X, quad, cube, sqrt, invr], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = AddNonlin()\n",
    "t = N.fit_transform(train[numerical_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Skewness Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unskew(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.skewness = X.apply(lambda x: skew(x))\n",
    "        self.skewness = self.skewness[abs(self.skewness) > 0.5]\n",
    "        self.skewed_features = self.skewness.index\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X[self.skewed_features] = np.log1p(X[self.skewed_features])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.X Numerical Feature Engineering Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feature_eng_pipeline = Pipeline([\n",
    "    ('selec_num', DataFrameSelector(numerical_features, dtype='df')), # input and output types = dataFrame\n",
    "    ('nonlinearity', AddNonlin(k=20)), # this need target to fit cann't drop SalePrice yet\n",
    "    ('fillnan', FillNAN()), # input and output types = dataFrame\n",
    "    ('drop_SalePrice', DataFrameSelector(numerical_features, method='all-drop', dtype='df')), \n",
    "    # input and output types = dataFrame\n",
    "    # SalePrice is dropped\n",
    "    # everything \n",
    "    ('unskew', Unskew()),\n",
    "    #('selector_array', DataFrameSelector(numerical_features, method='all', dtype='array')),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = num_feature_eng_pipeline.fit_transform(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Categorical Features Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 Fill missing values by most frequent values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FillCatNan(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.imputer = SimpleImputer(missing_values='nan', strategy='most_frequent')\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.imputer.fit(X.astype(str))\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return self.imputer.transform(X.astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLabelEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.encoders = []\n",
    "    \n",
    "    def fit(self, x, y=0):\n",
    "        X = x.transpose()\n",
    "        self.encoders = []\n",
    "        \n",
    "        \n",
    "        for i in range(X.shape[0]):\n",
    "            l = LabelEncoder()\n",
    "            l.fit(X[i])\n",
    "            self.encoders.append(l)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def transform(self, x, y=0):\n",
    "        X = x.transpose()\n",
    "        for i, l in enumerate(self.encoders):\n",
    "            #print(i)\n",
    "            X[i] = l.transform(X[i])\n",
    "        \n",
    "        return X.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.3 OneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyOneHotEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.onehot = OneHotEncoder()\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.onehot.fit(X)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return self.onehot.transform(X).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.X Categorical Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feature_eng_pipeline = Pipeline([\n",
    "    ('selec_cat', DataFrameSelector(categorical_features, dtype='df')), # i/o type = df\n",
    "    ('fill_by_mode', FillCatNan()), # output is array\n",
    "    ('encoder', MyLabelEncoder()),\n",
    "    ('onehot', MyOneHotEncoder()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c = cat_feature_eng_pipeline.fit_transform(train)\n",
    "#c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "    (\"num_feature_eng_pipeline\", num_feature_eng_pipeline),\n",
    "    (\"cat_feature_eng_pipeline\", cat_feature_eng_pipeline),\n",
    "])\n",
    "\n",
    "housing_prepared = full_pipeline.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 342)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_prepared.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Test Case Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1459, 80)\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('data/test.csv').drop(['Id'], axis=1)\n",
    "test = pd.concat([test, pd.DataFrame({'SalePrice' : [0]})]).iloc[:-1,:]\n",
    "test['SalePrice'] = 1\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1459, 86)\n"
     ]
    }
   ],
   "source": [
    "test = P.transform(test, outlier=False)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test = full_pipeline.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['SalePrice'].values\n",
    "\n",
    "shuffle_index = np.random.permutation(y.shape[0])\n",
    "housing_prepared, y = housing_prepared[shuffle_index], y[shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(model, cv=10):\n",
    "    reg_score = cross_val_score(model, housing_prepared, y, scoring='neg_mean_squared_error', cv=cv)\n",
    "    s = np.sqrt(-reg_score)\n",
    "    print('scores:', s)\n",
    "    print('mean score:', s.mean())\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(model):\n",
    "    model.fit(housing_prepared, y)\n",
    "    ypred = np.exp(model.predict(test))\n",
    "    Id = list(range(1461, 2920))\n",
    "    output = pd.DataFrame({'Id': Id, 'SalePrice' : ypred})\n",
    "    with open('submit.csv', 'w') as f:\n",
    "        f.write(output.to_csv(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.13007893 9.70177899 0.14619136 0.15517907 0.1770308  0.12441692\n",
      " 0.14942105 0.21484887 1.24738044 0.106041  ]\n",
      "mean score: 1.2152367439796685\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg_scores = score_model(LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predict(LinearRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 l1 Regularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.11371078 0.12116999 0.10540151 0.12282519 0.12484305 0.11190368\n",
      " 0.13169205 0.16582415 0.15029146 0.08782647]\n",
      "mean score: 0.123548832607889\n"
     ]
    }
   ],
   "source": [
    "lasso = LassoCV(alphas=[0.0001, 0.0002, 0.0004, 0.0006, 0.0008, 0.001, 0.002, \n",
    "                          0.004, 0.006, 0.008, 0.01, 0.02, 0.04, 0.06, 0.08, 0.1, 0.5, 1, 2,5,10], cv=10)\n",
    "lasso_reg_sores = score_model(lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predict(lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 l2 Regularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.12193188 0.12400835 0.11106818 0.13081762 0.12067149 0.11464279\n",
      " 0.13563227 0.16978367 0.15303497 0.08963942]\n",
      "mean score: 0.12712306285546782\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "ridge = RidgeCV(alphas=[0.01, 0.02, 0.04, 0.06, 0.1, 0.5, 1, 2,5,10, 20, 22, 24, 26, 28, 30, 32], cv=10)\n",
    "ridge_reg_sores = score_model(ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4 l1 and l2 Regularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.0001, 0.0002, 0.0004, 0.0006, 0.0008, 0.001, 0.002, \n",
    "                          0.004, 0.006, 0.008, 0.01, 0.02, 0.04, 0.06, 0.08, 0.1, 0.5, 0.8, 0.9, 0.95, 1, 1.1, 2,5,10] \n",
    "elasticNet = ElasticNetCV(l1_ratio = [0.1, 0.3, 0.5, 0.6, 0.7, 0.8, 0.85, 0.9, 0.95, 1],\n",
    "                          alphas = alphas, \n",
    "                          max_iter = 50000, cv = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.12364123 0.13417067]\n",
      "mean score: 0.12890594926064158\n"
     ]
    }
   ],
   "source": [
    "elasticNet_score = score_model(elasticNet, cv=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.14049716 0.14224561 0.13679382 0.14391492 0.14234535 0.12344555\n",
      " 0.14687628 0.14292183 0.16881085 0.12549851]\n",
      "mean score: 0.14133498719412493\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_reg_scores = score_model(RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
